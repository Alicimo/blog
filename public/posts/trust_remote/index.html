<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Losing Trust Remote | Words &amp; Stuff</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Currently, like a large portion of data scientists, I am working on a Generative AI (read: NLP) product. This has drawn me into the eco-system of HuggingFace and their excellent python packages. However, regardless of the high-quality documentation, things may still be unclear. This was the case with the trust_remote_code flag, which defaults to False. The docstring for this flag is

trust_remote_code (bool_,_ optional) – Whether or not to allow for custom models defined on the Hub in their own modeling files. This option should only be set to True for repositories you trust and in which you have read the code, as it will execute code present on the Hub on your local machine.">
    <meta name="generator" content="Hugo 0.143.0">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    

    
      

    

    

    
      <link rel="canonical" href="http://localhost:1313/posts/trust_remote/">
    

    <meta property="og:url" content="http://localhost:1313/posts/trust_remote/">
  <meta property="og:site_name" content="Words & Stuff">
  <meta property="og:title" content="Losing Trust Remote">
  <meta property="og:description" content="Currently, like a large portion of data scientists, I am working on a Generative AI (read: NLP) product. This has drawn me into the eco-system of HuggingFace and their excellent python packages. However, regardless of the high-quality documentation, things may still be unclear. This was the case with the trust_remote_code flag, which defaults to False. The docstring for this flag is
trust_remote_code (bool_,_ optional) – Whether or not to allow for custom models defined on the Hub in their own modeling files. This option should only be set to True for repositories you trust and in which you have read the code, as it will execute code present on the Hub on your local machine.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-12-28T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-12-28T00:00:00+00:00">

  <meta itemprop="name" content="Losing Trust Remote">
  <meta itemprop="description" content="Currently, like a large portion of data scientists, I am working on a Generative AI (read: NLP) product. This has drawn me into the eco-system of HuggingFace and their excellent python packages. However, regardless of the high-quality documentation, things may still be unclear. This was the case with the trust_remote_code flag, which defaults to False. The docstring for this flag is
trust_remote_code (bool_,_ optional) – Whether or not to allow for custom models defined on the Hub in their own modeling files. This option should only be set to True for repositories you trust and in which you have read the code, as it will execute code present on the Hub on your local machine.">
  <meta itemprop="datePublished" content="2024-12-28T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-12-28T00:00:00+00:00">
  <meta itemprop="wordCount" content="568">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Losing Trust Remote">
  <meta name="twitter:description" content="Currently, like a large portion of data scientists, I am working on a Generative AI (read: NLP) product. This has drawn me into the eco-system of HuggingFace and their excellent python packages. However, regardless of the high-quality documentation, things may still be unclear. This was the case with the trust_remote_code flag, which defaults to False. The docstring for this flag is
trust_remote_code (bool_,_ optional) – Whether or not to allow for custom models defined on the Hub in their own modeling files. This option should only be set to True for repositories you trust and in which you have read the code, as it will execute code present on the Hub on your local machine.">

	
  </head><body class="ma0 avenir bg-near-white development">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        <img src="/logo.webp" class="w100 mw5-ns" alt="Words &amp; Stuff" />
      
    </a>
    <div class="flex-l items-center">
      

      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Posts
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">Losing Trust Remote</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2024-12-28T00:00:00Z">December 28, 2024</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>Currently, like a large portion of data scientists, I am working on a Generative AI (read: NLP) product. This has drawn me into the eco-system of HuggingFace and their excellent python packages. However, regardless of the high-quality documentation, things may still be unclear. This was the case with the <code>trust_remote_code</code> flag, which defaults to <code>False</code>. The docstring for this flag is</p>
<blockquote>
<p><strong>trust_remote_code</strong> (<em>bool</em>_,_ <em>optional</em>) – Whether or not to allow for custom models defined on the Hub in their own modeling files. This option should only be set to True for repositories you trust and in which you have read the code, as it will execute code present on the Hub on your local machine.</p></blockquote>
<p>Given the word &ldquo;remote&rdquo; in the flag, I presumed that this flag is only relevant for models downloaded from HF (or your local HF cache), i.e., those loaded via <code>SentenceTransformer(&quot;[MODEL_NAME]&quot;, trust_remote_code=True)</code>. This is further reinforced when by the mention of &ldquo;repositories&rdquo; and &ldquo;code present on the Hub&rdquo;. However, as I&rsquo;ll show below, this is not the case.</p>
<p>In the current product, we would download the model in the first stage and use it to process some data. We would then use the same model again at a later stage within the product. Until now, we used base-models, meaning that we could use the above call to load the model at both points, the cache being used on the second requests. Also, our model choice meant we had to set <code>trust_remote_code = True</code>.</p>
<p>In my feature, I was changing this to save the model at the given location locally, which would specified in the second call. This was a preliminary change to allow for fine-tuning the model, and therefore altering it from the version supplied by HF, in the near future. This led to the following code:</p>
<pre tabindex="0"><code># STAGE 1
model_1 = SentenceTransformer(&#34;[MODEL_NAME]&#34;, trust_remote_code=True)
...(data processing)...
model_1.save(&#34;local/dir&#34;)

# STAGE 2
model_2 = SentenceTransformer(&#34;local/dir&#34;)
...
</code></pre><p>The first thing to note is that the above pipeline does not produce any warnings and/or errors when loading the model the second time. Further, <code>model_2</code> can be used as expected; namely the remaining code in stage two runs to completion. However, I found that the outcome was drastically different. Namely,</p>
<pre tabindex="0"><code>model_1.embed([&#34;Ah! A cat&#34;]) == model_2.embed([&#34;Ah! A cat&#34;])
# False
</code></pre><p>Embeddings generated by <code>model_2</code> are different! This change drastically changed the performance of our product because we had processed the data using <code>model_1</code>. Thankfully our pipeline caught this change and nothing made it to production. Adding the removed flag reverts the behaviour to that expected.</p>
<pre tabindex="0"><code>model_3 = SentenceTransformer(&#34;local/dir&#34;, trust_remote_code=True)
model_1.embed([&#34;Ah! A cat&#34;]) == model_3.embed([&#34;Ah! A cat&#34;])
# True
</code></pre><p>The underlying reason for this is documented <a href="https://huggingface.co/docs/transformers/custom_models#building-custom-models">here</a>. The <code>remote_code_true</code> flag indicates whether a model is fully encapsulated by the Transformers package. Models that rely on code not present in this package, i.e., custom functions or additional packages, require one requires the flag be set.  Given this, I do not understand why <code>model_2</code> does not raise errors/warnings when loaded without said flag or when it produces embeddings.  If it does not need the remote code to produce embeddings, why do I need it when loading <code>model_1</code>?</p>
<p>While simple on the surface, this bug, wrapped up with other changes on a code base I was unfamiliar with, cost me more time than I would like to admit. If google has served you this blog post in your debugging search, I hope it helps.</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/" >
    &copy;  Words & Stuff 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
